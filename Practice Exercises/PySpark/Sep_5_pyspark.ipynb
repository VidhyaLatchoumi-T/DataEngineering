{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "62f8c94ef6f34f71a381504293b7e18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "age",
              "salary"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Filter By:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_c70219d0c1774efaa209ad4ff998a0c4",
            "style": "IPY_MODEL_fa484f5c6d76470b9df15b71676f5026"
          }
        },
        "c70219d0c1774efaa209ad4ff998a0c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa484f5c6d76470b9df15b71676f5026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c194975d78b450eb5ad209f231f991c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": false,
            "description": "Threshold:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1d5c2ee6e001424eb63571a40f014d0a",
            "max": 100,
            "min": 20,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 5,
            "style": "IPY_MODEL_bc27b9311c774ffeb874318fef1800b6",
            "value": 40
          }
        },
        "1d5c2ee6e001424eb63571a40f014d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc27b9311c774ffeb874318fef1800b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "1ea13a966b834dd0948d24606e1f91ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Apply Filter",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a7b125d718f84a5ba636788266febf27",
            "style": "IPY_MODEL_7dcebbec1e3f4585a1d469a9cfca40ac",
            "tooltip": ""
          }
        },
        "a7b125d718f84a5ba636788266febf27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dcebbec1e3f4585a1d469a9cfca40ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8a6c818ddea84016bf750d82494205f6": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0b1dbd83deee4b628e6fca0c6ef12425",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Filtering by (column) > (threshold)\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "+----+---+------+------+\n",
                  "|name|age|gender|salary|\n",
                  "+----+---+------+------+\n",
                  "|Mike| 45|  Male| 84000|\n",
                  "+----+---+------+------+\n",
                  "\n"
                ]
              }
            ]
          }
        },
        "0b1dbd83deee4b628e6fca0c6ef12425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKGhL06sk0vC",
        "outputId": "73290324-aad5-48b5-e519-015ab80ddd95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=2fc76b7d43c0c558bbba97f4a71851e8750e1594e11503a20ac9c132ae1bc20c\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark=SparkSession.builder \\\n",
        "  .appName(\"RDD Transformation\") \\\n",
        "  .getOrCreate()\n",
        "\n",
        "sc=spark.sparkContext"
      ],
      "metadata": {
        "id": "wb8ts848JsnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[1,2,3,4,5,6,7,8,9,10]\n",
        "rdd=sc.parallelize(data)\n",
        "print(\"Original rdd:\",rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69Fp8CjQKbPE",
        "outputId": "2a78b336-6488-4f87-b1f5-ebc4c83d005c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rdd: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2=rdd.map(lambda x: x*2)\n",
        "print(\"rdd after multiplication:\",rdd2.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PkuVR1wK63m",
        "outputId": "1a438673-cbdc-49f6-edaa-0e9bc58cecd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rdd after multiplication: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd3=rdd.filter(lambda x: x%2==0)\n",
        "print(\"rdd with only even numbers:\",rdd3.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6oQ1XAxLOtv",
        "outputId": "5b953aea-2754-45b0-93bf-d067404d5cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rdd with only even numbers: [2, 4, 6, 8, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=[\"Hello world\",\"Pyspark is great\",\"RDD transformations are explained\"]\n",
        "rdd4=sc.parallelize(sentences)\n",
        "words_rdd=rdd4.flatMap(lambda sentence: sentence.split(\" \"))\n",
        "print(\"rdd after flatmap:\",words_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaCCFbtnMfbp",
        "outputId": "78cf08b5-7e4c-4651-f248-f0a900d4f67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rdd after flatmap: ['Hello', 'world', 'Pyspark', 'is', 'great', 'RDD', 'transformations', 'are', 'explained']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results=rdd3.collect()\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn1anMGjRnyV",
        "outputId": "fa9d78ff-abcb-4030-ba61-1eeba5a7f767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=rdd3.count()\n",
        "print(\"Number of elements:\", count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMjw91FwRsQx",
        "outputId": "1a1df8e7-f4f3-41fd-e165-303a3dcb06d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of elements: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total=rdd.reduce(lambda x,y:x+y)\n",
        "print(\"Total sum:\",total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ5m6BBXR3QC",
        "outputId": "3ba3fc1e-b752-448d-a6fb-bd3ad5570f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sum: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Initialize SparkSession and SparkContext:\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Key-Value Pair RDDs Exercise\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "0zn2TuuGTyE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 1: Create an RDD from the Sales Data\n",
        "sales_data = [\n",
        "    (\"ProductA\", 100),\n",
        "    (\"ProductB\", 150),\n",
        "    (\"ProductA\", 200),\n",
        "    (\"ProductC\", 300),\n",
        "    (\"ProductB\", 250),\n",
        "    (\"ProductC\", 100)\n",
        "]\n",
        "\n",
        "sales_rdd = sc.parallelize(sales_data)\n",
        "\n",
        "print(\"Sales RDD:\")\n",
        "print(sales_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTN1s6oYUCpy",
        "outputId": "03a5befc-4480-4567-ad9f-f9f67b6c8344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sales RDD:\n",
            "[('ProductA', 100), ('ProductB', 150), ('ProductA', 200), ('ProductC', 300), ('ProductB', 250), ('ProductC', 100)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 2: Group Data by Product Name\n",
        "grouped_sales_rdd = sales_rdd.groupByKey()\n",
        "grouped_sales_data = grouped_sales_rdd.mapValues(list).collect()\n",
        "print(\"Grouped Sales RDD:\")\n",
        "for product, sales in grouped_sales_data:\n",
        "    print(f\"{product}: {sales}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plSzOnS9UgUT",
        "outputId": "5ca724ed-f75f-4deb-c4fe-754c46a8f093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grouped Sales RDD:\n",
            "ProductA: [100, 200]\n",
            "ProductB: [150, 250]\n",
            "ProductC: [300, 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3: Calculate Total Sales by Product\n",
        "total_sales_rdd = sales_rdd.reduceByKey(lambda a, b: a + b)\n",
        "print(\"Total Sales by Product:\")\n",
        "print(total_sales_rdd.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjhK13zwU0zV",
        "outputId": "ca6207e8-ad26-4ca5-8903-992656fada8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sales by Product:\n",
            "[('ProductA', 300), ('ProductB', 400), ('ProductC', 400)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 4: Sort Products by Total Sales\n",
        "sorted_sales_rdd = total_sales_rdd.sortBy(lambda x: x[1], ascending=False)\n",
        "print(\"Sorted Products by Total Sales:\")\n",
        "print(sorted_sales_rdd.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_oI7gq8U6q9",
        "outputId": "faf7d081-50db-4c26-ee5a-ae74443df0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted Products by Total Sales:\n",
            "[('ProductB', 400), ('ProductC', 400), ('ProductA', 300)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 5: Filter Products with High Sales\n",
        "high_sales_rdd = total_sales_rdd.filter(lambda x: x[1] > 200)\n",
        "print(\"Products with Sales Greater than 200:\")\n",
        "print(high_sales_rdd.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8MIJ8X6VCk0",
        "outputId": "ee874f00-ac57-4960-83b5-60cdaf50fe50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Products with Sales Greater than 200:\n",
            "[('ProductA', 300), ('ProductB', 400), ('ProductC', 400)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 6: Combine Regional Sales Data\n",
        "regional_sales_data = [\n",
        "    (\"ProductA\", 50),\n",
        "    (\"ProductC\", 150)\n",
        "]\n",
        "regional_sales_rdd = sc.parallelize(regional_sales_data)\n",
        "\n",
        "combined_sales_rdd = sales_rdd.union(regional_sales_rdd)\n",
        "\n",
        "combined_total_sales_rdd = combined_sales_rdd.reduceByKey(lambda a, b: a + b)\n",
        "print(\"Combined Sales Data:\")\n",
        "print(combined_total_sales_rdd.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASxfl1I3VK9Q",
        "outputId": "4e745dcf-ac61-42db-b94e-0b1e040220af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Sales Data:\n",
            "[('ProductA', 350), ('ProductC', 550), ('ProductB', 400)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 7: Count the Number of Distinct Products\n",
        "distinct_product_count = combined_total_sales_rdd.count()\n",
        "print(f\"Number of Distinct Products: {distinct_product_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVV4wSUzVVAn",
        "outputId": "374f9e4c-0fa9-4bb1-aaf5-175423ebb070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Distinct Products: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8: Identify the Product with Maximum Sales\n",
        "max_sales_product = combined_total_sales_rdd.reduce(lambda x, y: x if x[1] > y[1] else y)\n",
        "print(f\"Product with Maximum Sales: {max_sales_product}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLlIiRsMVfXX",
        "outputId": "cad57c34-3c46-46a2-8fbb-60faf1c9a7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product with Maximum Sales: ('ProductC', 550)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Challenge Task: Calculate the Average Sales per Product\n",
        "grouped_sales_rdd = combined_sales_rdd.groupByKey()\n",
        "average_sales_rdd = grouped_sales_rdd.mapValues(lambda sales: sum(sales) / len(sales))\n",
        "print(\"Average Sales per Product:\")\n",
        "print(average_sales_rdd.collect())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbqs40f2VpTk",
        "outputId": "6632e196-d98e-4c3f-922d-1400dcf68969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sales per Product:\n",
            "[('ProductA', 116.66666666666667), ('ProductC', 183.33333333333334), ('ProductB', 200.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize a Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Employee Data Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Sample employee data\n",
        "data = [\n",
        "    (1, 'Arjun', 'IT', 75000),\n",
        "    (2, 'Vijay', 'Finance', 85000),\n",
        "    (3, 'Shalini', 'IT', 90000),\n",
        "    (4, 'Sneha', 'HR', 50000),\n",
        "    (5, 'Rahul', 'Finance', 60000),\n",
        "    (6, 'Amit', 'IT', 55000)\n",
        "]\n",
        "\n",
        "# Define schema (columns)\n",
        "columns = ['EmployeeID', 'EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "# Create DataFrame\n",
        "employee_df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Show the DataFrame\n",
        "employee_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA9R8-4IKUiG",
        "outputId": "acc7940b-c94a-4e35-be34-c757854efeb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+----------+------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|\n",
            "+----------+------------+----------+------+\n",
            "|         1|       Arjun|        IT| 75000|\n",
            "|         2|       Vijay|   Finance| 85000|\n",
            "|         3|     Shalini|        IT| 90000|\n",
            "|         4|       Sneha|        HR| 50000|\n",
            "|         5|       Rahul|   Finance| 60000|\n",
            "|         6|        Amit|        IT| 55000|\n",
            "+----------+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Filter Employees by Salary\n",
        "filtered_df = employee_df.filter(col('Salary') > 60000)\n",
        "filtered_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7mSdhumKpbC",
        "outputId": "2c146f00-ff9a-4fcc-bed7-96945dd079e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+----------+------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|\n",
            "+----------+------------+----------+------+\n",
            "|         1|       Arjun|        IT| 75000|\n",
            "|         2|       Vijay|   Finance| 85000|\n",
            "|         3|     Shalini|        IT| 90000|\n",
            "+----------+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Calculate the Average Salary by Department\n",
        "from pyspark.sql.functions import avg\n",
        "avg_salary_df = employee_df.groupBy('Department').agg(avg('Salary').alias('AverageSalary'))\n",
        "avg_salary_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0ux9s3HKu9z",
        "outputId": "b0e5d74c-fd5f-4c7b-9a2c-6a165153d7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+\n",
            "|Department|    AverageSalary|\n",
            "+----------+-----------------+\n",
            "|   Finance|          72500.0|\n",
            "|        IT|73333.33333333333|\n",
            "|        HR|          50000.0|\n",
            "+----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Sort Employees by Salary\n",
        "sorted_df = employee_df.orderBy(col('Salary').desc())\n",
        "sorted_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Hdiy5KK4M8",
        "outputId": "d7667aea-d0c4-41e2-9198-39b5658bd0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+----------+------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|\n",
            "+----------+------------+----------+------+\n",
            "|         3|     Shalini|        IT| 90000|\n",
            "|         2|       Vijay|   Finance| 85000|\n",
            "|         1|       Arjun|        IT| 75000|\n",
            "|         5|       Rahul|   Finance| 60000|\n",
            "|         6|        Amit|        IT| 55000|\n",
            "|         4|       Sneha|        HR| 50000|\n",
            "+----------+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Add a Bonus Column\n",
        "from pyspark.sql.functions import expr\n",
        "employee_with_bonus_df = employee_df.withColumn('Bonus', col('Salary') * 0.10)\n",
        "employee_with_bonus_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BFByn7PK8oJ",
        "outputId": "bcc21245-20a5-40b8-a4aa-e34b7335df93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+----------+------+------+\n",
            "|EmployeeID|EmployeeName|Department|Salary| Bonus|\n",
            "+----------+------------+----------+------+------+\n",
            "|         1|       Arjun|        IT| 75000|7500.0|\n",
            "|         2|       Vijay|   Finance| 85000|8500.0|\n",
            "|         3|     Shalini|        IT| 90000|9000.0|\n",
            "|         4|       Sneha|        HR| 50000|5000.0|\n",
            "|         5|       Rahul|   Finance| 60000|6000.0|\n",
            "|         6|        Amit|        IT| 55000|5500.0|\n",
            "+----------+------------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the entire DataFrame to CSV\n",
        "employee_df.write.csv('employee_data1.csv', header=True)\n"
      ],
      "metadata": {
        "id": "6Mc1Z2KltWNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark=SparkSession.builder \\\n",
        ".appName(\"Employee Data Handling\") \\\n",
        ".getOrCreate ()\n",
        "\n",
        "data = [\n",
        "    (1, 'Arjun', 'IT', 75000),\n",
        "    (2, 'Vijay', 'Finance', 85000),\n",
        "    (3, None, 'IT', 90000),\n",
        "    (4, 'Sneha', 'HR', None),\n",
        "    (5, 'Rahul', None, 60000),\n",
        "    (6, 'Amit', 'IT', 55000)\n",
        "]\n",
        "\n",
        "columns = ['EmployeeID', 'EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "employee_df =spark.createDataFrame (data, columns)\n",
        "\n",
        "# Show the DataFrame\n",
        "employee_df.show()\n",
        "\n",
        "# Fill null values in 'EmployeeName' and 'Department' with 'Unknown'\n",
        "filled_df= employee_df.fillna({'EmployeeName': 'Unknown', 'Department': 'Unknown'})\n",
        "filled_df.show()\n",
        "\n",
        "# Drop rows where 'Salary' is null\n",
        "dropped_null_salary_df = employee_df.dropna (subset=['Salary'])\n",
        "dropped_null_salary_df.show()\n",
        "\n",
        "# Fill null values in 'Salary' with 50000\n",
        "salary_filled_df=employee_df.fillna({'Salary': 50000})\n",
        "salary_filled_df.show()\n",
        "\n",
        "# Check for null values in the entire DataFrame\n",
        "null_counts= employee_df.select([col(c).isNull().alias (c) for c in employee_df.columns]).show()\n",
        "\n",
        "# Replace all null values in the DataFrame with 'N/A'\n",
        "na_filled_df = employee_df.na.fill('N/A')\n",
        "na_filled_df.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX8N9Zbi3JaS",
        "outputId": "ef5733c9-cdd6-4db4-b006-e044d0e9fc55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+----------+------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|\n",
            "+----------+------------+----------+------+\n",
            "|         1|       Arjun|        IT| 75000|\n",
            "|         2|       Vijay|   Finance| 85000|\n",
            "|         3|        NULL|        IT| 90000|\n",
            "|         4|       Sneha|        HR|  NULL|\n",
            "|         5|       Rahul|      NULL| 60000|\n",
            "|         6|        Amit|        IT| 55000|\n",
            "+----------+------------+----------+------+\n",
            "\n",
            "+----------+------------+----------+------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|\n",
            "+----------+------------+----------+------+\n",
            "|         1|       Arjun|        IT| 75000|\n",
            "|         2|       Vijay|   Finance| 85000|\n",
            "|         3|     Unknown|        IT| 90000|\n",
            "|         4|       Sneha|        HR|  NULL|\n",
            "|         5|       Rahul|   Unknown| 60000|\n",
            "|         6|        Amit|        IT| 55000|\n",
            "+----------+------------+----------+------+\n",
            "\n",
            "+----------+------------+----------+------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|\n",
            "+----------+------------+----------+------+\n",
            "|         1|       Arjun|        IT| 75000|\n",
            "|         2|       Vijay|   Finance| 85000|\n",
            "|         3|        NULL|        IT| 90000|\n",
            "|         5|       Rahul|      NULL| 60000|\n",
            "|         6|        Amit|        IT| 55000|\n",
            "+----------+------------+----------+------+\n",
            "\n",
            "+----------+------------+----------+------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|\n",
            "+----------+------------+----------+------+\n",
            "|         1|       Arjun|        IT| 75000|\n",
            "|         2|       Vijay|   Finance| 85000|\n",
            "|         3|        NULL|        IT| 90000|\n",
            "|         4|       Sneha|        HR| 50000|\n",
            "|         5|       Rahul|      NULL| 60000|\n",
            "|         6|        Amit|        IT| 55000|\n",
            "+----------+------------+----------+------+\n",
            "\n",
            "+----------+------------+----------+------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|\n",
            "+----------+------------+----------+------+\n",
            "|     false|       false|     false| false|\n",
            "|     false|       false|     false| false|\n",
            "|     false|        true|     false| false|\n",
            "|     false|       false|     false|  true|\n",
            "|     false|       false|      true| false|\n",
            "|     false|       false|     false| false|\n",
            "+----------+------------+----------+------+\n",
            "\n",
            "+----------+------------+----------+------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|\n",
            "+----------+------------+----------+------+\n",
            "|         1|       Arjun|        IT| 75000|\n",
            "|         2|       Vijay|   Finance| 85000|\n",
            "|         3|         N/A|        IT| 90000|\n",
            "|         4|       Sneha|        HR|  NULL|\n",
            "|         5|       Rahul|       N/A| 60000|\n",
            "|         6|        Amit|        IT| 55000|\n",
            "+----------+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "# Initialize a Spark session\n",
        "spark= SparkSession.builder \\\n",
        ".appName(\"Advanced DataFrame Operations\") \\\n",
        ".getOrCreate ()\n",
        "# Create two sample DataFrames\n",
        "datal = [\n",
        "    (1, 'Arjun', 'IT', 75000, '2022-01-15'), (2, 'Vijay', 'Finance', 85000, '2022-03-12'), (3, 'Shalini', 'IT', 90000, '2021-06-30')\n",
        "]\n",
        "data2 = [\n",
        "(4, 'Sneha', 'HR', 50000, '2022-05-01'), (5, 'Rahul', 'Finance', 60000, '2022-08-20'), (6, 'Amit', 'IT', 55000, '2021-12-15')\n",
        "]\n",
        "#Define schema (columns)\n",
        "columns = ['EmployeeID', 'EmployeeName', 'Department', 'Salary', 'JoiningDate']\n",
        "#Create DataFrames\n",
        "employee_df1 = spark.createDataFrame (datal, columns)\n",
        "employee_df2 = spark.createDataFrame (data2, columns)\n",
        "\n",
        "#Union of two DataFrames (removes duplicates)\n",
        "union_df=employee_df1.union (employee_df2).dropDuplicates()\n",
        "union_df.show()\n",
        "#Union of two DataFrames (includes duplicates)\n",
        "union_all_df= employee_df1.union(employee_df2)\n",
        "union_all_df.show()\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank\n",
        "#Define a window specification to rank employees by salary within each department\n",
        "window_spec=Window.partitionBy(\"Department\").orderBy (col (\"Salary\").desc())\n",
        "#Add a rank column to the DataFrame\n",
        "ranked_df= union_all_df.withColumn (\"Rank\", rank().over (window_spec))\n",
        "ranked_df.show()\n",
        "from pyspark.sql.functions import sum\n",
        "#Define a window specification for cumulative sum of salaries within each department\n",
        "window_spec_sum= Window.partitionBy(\"Department\").orderBy(\"JoiningDate\").rowsBetween (Window.unboundedPreceding, Window.currentRow)\n",
        "\n",
        "#Calculate the running total of salaries\n",
        "window_spec_sum = Window.orderBy(\"EmployeeID\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "running_total_df = union_all_df.withColumn(\"RunningTotal\", sum(col(\"Salary\")).over(window_spec_sum))\n",
        "running_total_df.show()\n",
        "#Convert JoiningDate from string to date type\n",
        "date_converted_df = union_all_df.withColumn(\"JoiningDate\", F.to_date(col(\"JoiningDate\"), \"yyyy-MM-dd\"))\n",
        "date_converted_df.show()\n",
        "#Calculate the number of years since joining\n",
        "experience_df=date_converted_df.withColumn (\"YearsOfExperience\", F.round (F.datediff (F.current_date(), col (\"JoiningDate\")) / 365, 2))\n",
        "experience_df.show()\n",
        "#Add a new column for next evaluation date (one year after joining)\n",
        "eval_date_df =date_converted_df.withColumn (\"NextEvaluationDate\", F.date_add(col (\"JoiningDate\"), 365))\n",
        "eval_date_df.show()\n",
        "#Calculate average salary per department\n",
        "avg_salary_df= union_all_df.groupBy(\"Department\").agg(F.avg(\"Salary\").alias(\"AverageSalary\"))\n",
        "avg_salary_df.show()\n",
        "#Calculate the total number of employees.\n",
        "total_employees_df= union_all_df.agg(F.count(\"EmployeeID\").alias (\"TotalEmployees\"))\n",
        "total_employees_df.show()\n",
        "#Convert employee names to uppercase\n",
        "upper_name_df =union_all_df.withColumn (\"EmployeeNameUpper\", F.upper (col(\"EmployeeName\")))\n",
        "upper_name_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuXzZ84XP0UT",
        "outputId": "ab3c3824-69bf-4491-cb7d-6ffd6ff37f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+----------+------+-----------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n",
            "+----------+------------+----------+------+-----------+\n",
            "|         1|       Arjun|        IT| 75000| 2022-01-15|\n",
            "|         3|     Shalini|        IT| 90000| 2021-06-30|\n",
            "|         2|       Vijay|   Finance| 85000| 2022-03-12|\n",
            "|         4|       Sneha|        HR| 50000| 2022-05-01|\n",
            "|         5|       Rahul|   Finance| 60000| 2022-08-20|\n",
            "|         6|        Amit|        IT| 55000| 2021-12-15|\n",
            "+----------+------------+----------+------+-----------+\n",
            "\n",
            "+----------+------------+----------+------+-----------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n",
            "+----------+------------+----------+------+-----------+\n",
            "|         1|       Arjun|        IT| 75000| 2022-01-15|\n",
            "|         2|       Vijay|   Finance| 85000| 2022-03-12|\n",
            "|         3|     Shalini|        IT| 90000| 2021-06-30|\n",
            "|         4|       Sneha|        HR| 50000| 2022-05-01|\n",
            "|         5|       Rahul|   Finance| 60000| 2022-08-20|\n",
            "|         6|        Amit|        IT| 55000| 2021-12-15|\n",
            "+----------+------------+----------+------+-----------+\n",
            "\n",
            "+----------+------------+----------+------+-----------+----+\n",
            "|EmployeeID|EmployeeName|Department|Salary|JoiningDate|Rank|\n",
            "+----------+------------+----------+------+-----------+----+\n",
            "|         2|       Vijay|   Finance| 85000| 2022-03-12|   1|\n",
            "|         5|       Rahul|   Finance| 60000| 2022-08-20|   2|\n",
            "|         4|       Sneha|        HR| 50000| 2022-05-01|   1|\n",
            "|         3|     Shalini|        IT| 90000| 2021-06-30|   1|\n",
            "|         1|       Arjun|        IT| 75000| 2022-01-15|   2|\n",
            "|         6|        Amit|        IT| 55000| 2021-12-15|   3|\n",
            "+----------+------------+----------+------+-----------+----+\n",
            "\n",
            "+----------+------------+----------+------+-----------+------------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|JoiningDate|RunningTotal|\n",
            "+----------+------------+----------+------+-----------+------------+\n",
            "|         1|       Arjun|        IT| 75000| 2022-01-15|       75000|\n",
            "|         2|       Vijay|   Finance| 85000| 2022-03-12|      160000|\n",
            "|         3|     Shalini|        IT| 90000| 2021-06-30|      250000|\n",
            "|         4|       Sneha|        HR| 50000| 2022-05-01|      300000|\n",
            "|         5|       Rahul|   Finance| 60000| 2022-08-20|      360000|\n",
            "|         6|        Amit|        IT| 55000| 2021-12-15|      415000|\n",
            "+----------+------------+----------+------+-----------+------------+\n",
            "\n",
            "+----------+------------+----------+------+-----------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n",
            "+----------+------------+----------+------+-----------+\n",
            "|         1|       Arjun|        IT| 75000| 2022-01-15|\n",
            "|         2|       Vijay|   Finance| 85000| 2022-03-12|\n",
            "|         3|     Shalini|        IT| 90000| 2021-06-30|\n",
            "|         4|       Sneha|        HR| 50000| 2022-05-01|\n",
            "|         5|       Rahul|   Finance| 60000| 2022-08-20|\n",
            "|         6|        Amit|        IT| 55000| 2021-12-15|\n",
            "+----------+------------+----------+------+-----------+\n",
            "\n",
            "+----------+------------+----------+------+-----------+-----------------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|JoiningDate|YearsOfExperience|\n",
            "+----------+------------+----------+------+-----------+-----------------+\n",
            "|         1|       Arjun|        IT| 75000| 2022-01-15|             2.64|\n",
            "|         2|       Vijay|   Finance| 85000| 2022-03-12|             2.48|\n",
            "|         3|     Shalini|        IT| 90000| 2021-06-30|             3.18|\n",
            "|         4|       Sneha|        HR| 50000| 2022-05-01|             2.35|\n",
            "|         5|       Rahul|   Finance| 60000| 2022-08-20|             2.04|\n",
            "|         6|        Amit|        IT| 55000| 2021-12-15|             2.72|\n",
            "+----------+------------+----------+------+-----------+-----------------+\n",
            "\n",
            "+----------+------------+----------+------+-----------+------------------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|JoiningDate|NextEvaluationDate|\n",
            "+----------+------------+----------+------+-----------+------------------+\n",
            "|         1|       Arjun|        IT| 75000| 2022-01-15|        2023-01-15|\n",
            "|         2|       Vijay|   Finance| 85000| 2022-03-12|        2023-03-12|\n",
            "|         3|     Shalini|        IT| 90000| 2021-06-30|        2022-06-30|\n",
            "|         4|       Sneha|        HR| 50000| 2022-05-01|        2023-05-01|\n",
            "|         5|       Rahul|   Finance| 60000| 2022-08-20|        2023-08-20|\n",
            "|         6|        Amit|        IT| 55000| 2021-12-15|        2022-12-15|\n",
            "+----------+------------+----------+------+-----------+------------------+\n",
            "\n",
            "+----------+-----------------+\n",
            "|Department|    AverageSalary|\n",
            "+----------+-----------------+\n",
            "|        IT|73333.33333333333|\n",
            "|   Finance|          72500.0|\n",
            "|        HR|          50000.0|\n",
            "+----------+-----------------+\n",
            "\n",
            "+--------------+\n",
            "|TotalEmployees|\n",
            "+--------------+\n",
            "|             6|\n",
            "+--------------+\n",
            "\n",
            "+----------+------------+----------+------+-----------+-----------------+\n",
            "|EmployeeID|EmployeeName|Department|Salary|JoiningDate|EmployeeNameUpper|\n",
            "+----------+------------+----------+------+-----------+-----------------+\n",
            "|         1|       Arjun|        IT| 75000| 2022-01-15|            ARJUN|\n",
            "|         2|       Vijay|   Finance| 85000| 2022-03-12|            VIJAY|\n",
            "|         3|     Shalini|        IT| 90000| 2021-06-30|          SHALINI|\n",
            "|         4|       Sneha|        HR| 50000| 2022-05-01|            SNEHA|\n",
            "|         5|       Rahul|   Finance| 60000| 2022-08-20|            RAHUL|\n",
            "|         6|        Amit|        IT| 55000| 2021-12-15|             AMIT|\n",
            "+----------+------------+----------+------+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Initialize a Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Advanced DataFrame Operations - Different Dataset\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Create two sample DataFrames for Product Sales\n",
        "data1 = [\n",
        "    (1, 'Product A', 'Electronics', 1200, '2022-05-10'),\n",
        "    (2, 'Product B', 'Clothing', 500, '2022-07-15'),\n",
        "    (3, 'Product C', 'Electronics', 1800, '2021-11-05')\n",
        "]\n",
        "\n",
        "data2 = [\n",
        "    (4, 'Product D', 'Furniture', 3000, '2022-03-25'),\n",
        "    (5, 'Product E', 'Clothing', 800, '2022-09-12'),\n",
        "    (6, 'Product F', 'Electronics', 1500, '2021-10-19')\n",
        "]\n",
        "\n",
        "# Define schema (columns)\n",
        "columns = ['ProductID', 'ProductName', 'Category', 'Price', 'SaleDate']\n",
        "\n",
        "# Create DataFrames\n",
        "sales_df1 = spark.createDataFrame(data1, columns)\n",
        "sales_df2 = spark.createDataFrame(data2, columns)"
      ],
      "metadata": {
        "id": "pR92BlANzc08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Union of DataFrames and remove duplicates\n",
        "union_df_distinct = sales_df1.union(sales_df2).distinct()\n",
        "union_df_distinct.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7UkyMuRz35C",
        "outputId": "bd6d1969-5a7d-45d0-8281-ceba80fdd158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+----------+\n",
            "|ProductID|ProductName|   Category|Price|  SaleDate|\n",
            "+---------+-----------+-----------+-----+----------+\n",
            "|        1|  Product A|Electronics| 1200|2022-05-10|\n",
            "|        2|  Product B|   Clothing|  500|2022-07-15|\n",
            "|        3|  Product C|Electronics| 1800|2021-11-05|\n",
            "|        4|  Product D|  Furniture| 3000|2022-03-25|\n",
            "|        6|  Product F|Electronics| 1500|2021-10-19|\n",
            "|        5|  Product E|   Clothing|  800|2022-09-12|\n",
            "+---------+-----------+-----------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Union of DataFrames including duplicates\n",
        "union_df_all = sales_df1.union(sales_df2)\n",
        "union_df_all.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs-uHRCP0Bml",
        "outputId": "e064109f-ab1d-4a13-aebf-f9bbd716e033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+----------+\n",
            "|ProductID|ProductName|   Category|Price|  SaleDate|\n",
            "+---------+-----------+-----------+-----+----------+\n",
            "|        1|  Product A|Electronics| 1200|2022-05-10|\n",
            "|        2|  Product B|   Clothing|  500|2022-07-15|\n",
            "|        3|  Product C|Electronics| 1800|2021-11-05|\n",
            "|        4|  Product D|  Furniture| 3000|2022-03-25|\n",
            "|        5|  Product E|   Clothing|  800|2022-09-12|\n",
            "|        6|  Product F|Electronics| 1500|2021-10-19|\n",
            "+---------+-----------+-----------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3: Rank Products by Price Within Their Category\n",
        "window_spec_rank = Window.partitionBy(\"Category\").orderBy(F.col(\"Price\").desc())\n",
        "ranked_df = union_df_all.withColumn(\"Rank\", F.rank().over(window_spec_rank))\n",
        "ranked_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9xeX7in0JgE",
        "outputId": "38673f24-80d3-4df6-bad0-a5e88823522d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+----------+----+\n",
            "|ProductID|ProductName|   Category|Price|  SaleDate|Rank|\n",
            "+---------+-----------+-----------+-----+----------+----+\n",
            "|        5|  Product E|   Clothing|  800|2022-09-12|   1|\n",
            "|        2|  Product B|   Clothing|  500|2022-07-15|   2|\n",
            "|        3|  Product C|Electronics| 1800|2021-11-05|   1|\n",
            "|        6|  Product F|Electronics| 1500|2021-10-19|   2|\n",
            "|        1|  Product A|Electronics| 1200|2022-05-10|   3|\n",
            "|        4|  Product D|  Furniture| 3000|2022-03-25|   1|\n",
            "+---------+-----------+-----------+-----+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 4: Calculate Cumulative Price per Category\n",
        "window_spec_cum_sum = Window.partitionBy(\"Category\").orderBy(\"Price\")\n",
        "cumulative_df = union_df_all.withColumn(\"CumulativePrice\", F.sum(\"Price\").over(window_spec_cum_sum))\n",
        "cumulative_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDfIkIrD0TR4",
        "outputId": "ad9b08d3-5c4a-4f82-8801-871fc3a54cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+----------+---------------+\n",
            "|ProductID|ProductName|   Category|Price|  SaleDate|CumulativePrice|\n",
            "+---------+-----------+-----------+-----+----------+---------------+\n",
            "|        2|  Product B|   Clothing|  500|2022-07-15|            500|\n",
            "|        5|  Product E|   Clothing|  800|2022-09-12|           1300|\n",
            "|        1|  Product A|Electronics| 1200|2022-05-10|           1200|\n",
            "|        6|  Product F|Electronics| 1500|2021-10-19|           2700|\n",
            "|        3|  Product C|Electronics| 1800|2021-11-05|           4500|\n",
            "|        4|  Product D|  Furniture| 3000|2022-03-25|           3000|\n",
            "+---------+-----------+-----------+-----+----------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 5: Convert SaleDate from String to Date Type\n",
        "date_converted_df = union_df_all.withColumn(\"SaleDate\", F.to_date(\"SaleDate\", \"yyyy-MM-dd\"))\n",
        "date_converted_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDvMuoUF0ahG",
        "outputId": "bdd5db3e-5189-49d7-e7b8-44c9e9b6a2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+----------+\n",
            "|ProductID|ProductName|   Category|Price|  SaleDate|\n",
            "+---------+-----------+-----------+-----+----------+\n",
            "|        1|  Product A|Electronics| 1200|2022-05-10|\n",
            "|        2|  Product B|   Clothing|  500|2022-07-15|\n",
            "|        3|  Product C|Electronics| 1800|2021-11-05|\n",
            "|        4|  Product D|  Furniture| 3000|2022-03-25|\n",
            "|        5|  Product E|   Clothing|  800|2022-09-12|\n",
            "|        6|  Product F|Electronics| 1500|2021-10-19|\n",
            "+---------+-----------+-----------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 6: Calculate the Number of Days Since Each Sale\n",
        "days_since_sale_df = date_converted_df.withColumn(\"DaysSinceSale\", F.datediff(F.current_date(), \"SaleDate\"))\n",
        "days_since_sale_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPY0b9pa0lLw",
        "outputId": "db3910c8-b0cc-4d40-e4c8-15e4295b7c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+----------+-------------+\n",
            "|ProductID|ProductName|   Category|Price|  SaleDate|DaysSinceSale|\n",
            "+---------+-----------+-----------+-----+----------+-------------+\n",
            "|        1|  Product A|Electronics| 1200|2022-05-10|          848|\n",
            "|        2|  Product B|   Clothing|  500|2022-07-15|          782|\n",
            "|        3|  Product C|Electronics| 1800|2021-11-05|         1034|\n",
            "|        4|  Product D|  Furniture| 3000|2022-03-25|          894|\n",
            "|        5|  Product E|   Clothing|  800|2022-09-12|          723|\n",
            "|        6|  Product F|Electronics| 1500|2021-10-19|         1051|\n",
            "+---------+-----------+-----------+-----+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 7: Add a Column for the Next Sale Deadline\n",
        "next_sale_deadline_df = date_converted_df.withColumn(\"NextSaleDeadline\",F.date_add(\"SaleDate\", 30))\n",
        "next_sale_deadline_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pckx5RqS2BHQ",
        "outputId": "6bd99a79-cc86-4d25-b5f8-f0320f54c15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+----------+----------------+\n",
            "|ProductID|ProductName|   Category|Price|  SaleDate|NextSaleDeadline|\n",
            "+---------+-----------+-----------+-----+----------+----------------+\n",
            "|        1|  Product A|Electronics| 1200|2022-05-10|      2022-06-09|\n",
            "|        2|  Product B|   Clothing|  500|2022-07-15|      2022-08-14|\n",
            "|        3|  Product C|Electronics| 1800|2021-11-05|      2021-12-05|\n",
            "|        4|  Product D|  Furniture| 3000|2022-03-25|      2022-04-24|\n",
            "|        5|  Product E|   Clothing|  800|2022-09-12|      2022-10-12|\n",
            "|        6|  Product F|Electronics| 1500|2021-10-19|      2021-11-18|\n",
            "+---------+-----------+-----------+-----+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8: Calculate Total Revenue and Average Price per Category\n",
        "revenue_avg_df = union_df_all.groupBy(\"Category\").agg(F.sum(\"Price\").alias(\"TotalRevenue\"),F.avg(\"Price\").alias(\"AveragePrice\"))\n",
        "revenue_avg_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvnzErMu2RuR",
        "outputId": "02e672a2-2588-4fff-828b-490c234ee77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+------------+\n",
            "|   Category|TotalRevenue|AveragePrice|\n",
            "+-----------+------------+------------+\n",
            "|Electronics|        4500|      1500.0|\n",
            "|   Clothing|        1300|       650.0|\n",
            "|  Furniture|        3000|      3000.0|\n",
            "+-----------+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 9: Convert All Product Names to Lowercase\n",
        "lowercase_names_df = union_df_all.withColumn(\"ProductNameLower\", F.lower(\"ProductName\"))\n",
        "lowercase_names_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOb4FlyE2kkE",
        "outputId": "43ee4e72-07ce-42a5-c8d7-5c3207891220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-----------+-----+----------+----------------+\n",
            "|ProductID|ProductName|   Category|Price|  SaleDate|ProductNameLower|\n",
            "+---------+-----------+-----------+-----+----------+----------------+\n",
            "|        1|  Product A|Electronics| 1200|2022-05-10|       product a|\n",
            "|        2|  Product B|   Clothing|  500|2022-07-15|       product b|\n",
            "|        3|  Product C|Electronics| 1800|2021-11-05|       product c|\n",
            "|        4|  Product D|  Furniture| 3000|2022-03-25|       product d|\n",
            "|        5|  Product E|   Clothing|  800|2022-09-12|       product e|\n",
            "|        6|  Product F|Electronics| 1500|2021-10-19|       product f|\n",
            "+---------+-----------+-----------+-----+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "  .appName(\"SparkSQLExample\")\\\n",
        "  .getOrCreate()\n"
      ],
      "metadata": {
        "id": "i6vNgr9AjclC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Full refresh: Load the entire dataset\n",
        "\n",
        "df_sales =  spark.read.format(\"csv\") \\\n",
        "        .option(\"header\", \"true\") \\\n",
        "        .option(\"inferSchema\", \"true\") \\\n",
        "        .load(\"/content/sales_data.csv\")\n",
        "\n",
        "#Apply transformations (if necessary)\n",
        "\n",
        "df_transformed = df_sales.withColumn(\"total_sales\", df_sales[\"quantity\"] * df_sales[\"price\"])\n",
        "\n",
        "#Full refresh: Partition the data by 'date' and overwrite the existing data\n",
        "\n",
        "output_path = \"/content/sample_data/partitioned_data\"\n",
        "\n",
        "df_transformed.write.partitionBy(\"date\").mode(\"overwrite\").parquet(output_path)\n",
        "\n",
        "#Verify partitioned data\n",
        "\n",
        "partitioned_df = spark.read.parquet(output_path)\n",
        "\n",
        "partitioned_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6ExB012lLmZ",
        "outputId": "3ef13d6c-d9e3-47dc-a65d-c9573105381b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+--------+--------+-----+-------------------+-----------+----------+\n",
            "|transaction_id|customer_id| product|quantity|price|         updated_at|total_sales|      date|\n",
            "+--------------+-----------+--------+--------+-----+-------------------+-----------+----------+\n",
            "|             1|        101|  Laptop|       1| 1000|2024-09-01 08:00:00|       1000|2024-09-01|\n",
            "|             2|        102|   Phone|       2|  500|2024-09-01 09:00:00|       1000|2024-09-01|\n",
            "|             5|        105|Keyboard|       1|   50|2024-09-03 12:00:00|         50|2024-09-03|\n",
            "|             6|        106|   Mouse|       3|   30|2024-09-03 13:00:00|         90|2024-09-03|\n",
            "|             3|        103|  Tablet|       1|  300|2024-09-02 10:00:00|        300|2024-09-02|\n",
            "|             4|        104| Monitor|       2|  200|2024-09-02 11:00:00|        400|2024-09-02|\n",
            "+--------------+-----------+--------+--------+-----+-------------------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"IncrementalLoad\").getOrCreate()\n",
        "\n",
        "# Define the last ETL run timestamp\n",
        "last_etl_run = '2024-09-01 00:00:00'\n",
        "\n",
        "# Load only new or updated records since the last ETL run\n",
        "df_incremental = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .load(\"/content/sample_data/sales_data.csv\") \\\n",
        "    .filter(F.col(\"updated_at\") > last_etl_run)\n",
        "\n",
        "# Apply transformations (if necessary)\n",
        "df_transformed_incremental = df_incremental.withColumn(\n",
        "    \"total_sales\", F.col(\"quantity\") * F.col(\"price\")\n",
        ")\n",
        "\n",
        "# Incremental load: Append the new data to the existing partitioned dataset\n",
        "output_path = \"/content/sample_data/partitioned_sales_data\"\n",
        "df_transformed_incremental.write.partitionBy(\"date\").mode(\"append\").parquet(output_path)\n",
        "\n",
        "# Verify partitioned data after incremental load\n",
        "partitioned_df = spark.read.parquet(output_path)\n",
        "partitioned_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YqD5iTLngj_",
        "outputId": "93f1bf6c-8f50-48c2-e908-0818c1d8c58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+--------+--------+-----+-------------------+-----------+----------+\n",
            "|transaction_id|customer_id| product|quantity|price|         updated_at|total_sales|      date|\n",
            "+--------------+-----------+--------+--------+-----+-------------------+-----------+----------+\n",
            "|             1|        101|  Laptop|       1| 1000|2024-09-01 08:00:00|       1000|2024-09-01|\n",
            "|             2|        102|   Phone|       2|  500|2024-09-01 09:00:00|       1000|2024-09-01|\n",
            "|             5|        105|Keyboard|       1|   50|2024-09-03 12:00:00|         50|2024-09-03|\n",
            "|             6|        106|   Mouse|       3|   30|2024-09-03 13:00:00|         90|2024-09-03|\n",
            "|             3|        103|  Tablet|       1|  300|2024-09-02 10:00:00|        300|2024-09-02|\n",
            "|             4|        104| Monitor|       2|  200|2024-09-02 11:00:00|        400|2024-09-02|\n",
            "+--------------+-----------+--------+--------+-----+-------------------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install ipywidgets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJjj8rszrh4T",
        "outputId": "20fc70bd-7477-4190-b1eb-e10031c9e2fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.8)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (71.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.2.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Step 1: Initialize a Spark session\n",
        "spark = SparkSession.builder.appName (\"PySpark with Widgets Example\").getOrCreate()\n",
        "# Step 2: Create a simple DataFrame\n",
        "data = [\n",
        "(\"John\", 28, \"Male\", 60000),\n",
        " (\"Jane\", 32, \"Female\", 72000),\n",
        "  (\"Mike\", 45, \"Male\", 84000),\n",
        "   (\"Emily\", 23, \"Female\", 52000),\n",
        "    (\"Alex\", 36, \"Male\", 67000)\n",
        "]\n",
        "df =spark.createDataFrame(data, [\"name\", \"age\", \"gender\", \"salary\"])\n",
        "# Show the DataFrame\n",
        "df.show()\n",
        "#Step 3: Create widgets\n",
        "# Dropdown widget to select column for filtering\n",
        "column_dropdown =widgets.Dropdown(\n",
        "    options=[\"age\", \"salary\"],\n",
        "    value=\"age\",\n",
        "    description=\"Filter By:\",\n",
        ")\n",
        "# Slider widget to choose a value for filtering\n",
        "slider =widgets. IntSlider(\n",
        "    value=30,\n",
        "    min=20,\n",
        "    max=100,\n",
        "    step=5,\n",
        "    description=\"Threshold:\",\n",
        "    continuous_update=False\n",
        ")\n",
        "#Button to trigger filtering\n",
        "button= widgets. Button (description=\"Apply Filter\")\n",
        "# Output area to show the results\n",
        "output= widgets. Output ()\n",
        "# Display the widgets\n",
        "display (column_dropdown, slider, button, output)\n",
        "# Step 4: Define the function to apply filtering based on widget inputs\n",
        "def apply_filter(b):\n",
        "  column = column_dropdown.value\n",
        "  threshold = slider.value\n",
        "# Clear previous output\n",
        "  output.clear_output()\n",
        "# Filter the DataFrame based on widget values\n",
        "  df_filtered =df.filter(df [column] > threshold)\n",
        "# Show the filtered DataFrame\n",
        "  with output:\n",
        "    print (f\"Filtering by (column) > (threshold)\")\n",
        "    df_filtered.show()\n",
        "#Step 5: Attach the function to the button click event\n",
        "button.on_click(apply_filter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "62f8c94ef6f34f71a381504293b7e18c",
            "c70219d0c1774efaa209ad4ff998a0c4",
            "fa484f5c6d76470b9df15b71676f5026",
            "3c194975d78b450eb5ad209f231f991c",
            "1d5c2ee6e001424eb63571a40f014d0a",
            "bc27b9311c774ffeb874318fef1800b6",
            "1ea13a966b834dd0948d24606e1f91ca",
            "a7b125d718f84a5ba636788266febf27",
            "7dcebbec1e3f4585a1d469a9cfca40ac",
            "8a6c818ddea84016bf750d82494205f6",
            "0b1dbd83deee4b628e6fca0c6ef12425"
          ]
        },
        "id": "trVdLEU3rnmi",
        "outputId": "3953b149-d353-4c62-c8b9-adcd2c1f81da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+------+------+\n",
            "| name|age|gender|salary|\n",
            "+-----+---+------+------+\n",
            "| John| 28|  Male| 60000|\n",
            "| Jane| 32|Female| 72000|\n",
            "| Mike| 45|  Male| 84000|\n",
            "|Emily| 23|Female| 52000|\n",
            "| Alex| 36|  Male| 67000|\n",
            "+-----+---+------+------+\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Filter By:', options=('age', 'salary'), value='age')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62f8c94ef6f34f71a381504293b7e18c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntSlider(value=30, continuous_update=False, description='Threshold:', min=20, step=5)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c194975d78b450eb5ad209f231f991c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Apply Filter', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ea13a966b834dd0948d24606e1f91ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a6c818ddea84016bf750d82494205f6"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}