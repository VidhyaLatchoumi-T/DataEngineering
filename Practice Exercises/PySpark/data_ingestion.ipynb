{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6L6C4r_PMK9",
        "outputId": "2fbbace0-9d96-4bf1-823e-18ec9b6b78db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=fa8c40c59e80e7785cb75de57f3de6530ace8e4e3a4ed5a904b14610c9d8c49e\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        ".appName('Data Ingestion')\\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "hb83Oox1XDA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path=\"/content/sample_data/people.csv\"\n",
        "\n",
        "df_csv=spark.read.format(\"csv\").option(\"header\",\"true\").load(csv_file_path)\n",
        "df_csv.show()"
      ],
      "metadata": {
        "id": "uFiTzIvJXaLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c2c8a26-fd67-4786-aeb8-c1a347689d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+------+\n",
            "|Name|Age|Gender|\n",
            "+----+---+------+\n",
            "|John| 28|  Male|\n",
            "|Jane| 32|Female|\n",
            "+----+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
        "\n",
        "# Define the schema for json file\n",
        "schema=StructType([\n",
        "    StructField(\"name\",StringType(),True),\n",
        "    StructField(\"age\",IntegerType(),True),\n",
        "    StructField(\"gender\",StringType(),True),\n",
        "    StructField(\"address\", StructType([\n",
        "        StructField(\"street\", StringType(), True),\n",
        "        StructField(\"city\", StringType(), True)\n",
        "    ]), True)\n",
        "])\n",
        "\n",
        "json_file_path=\"/content/sample_data/sample.json\"\n",
        "\n",
        "df_json_complex=spark.read.schema(schema).json(json_file_path)\n",
        "\n",
        "with open(json_file_path, 'r') as file:\n",
        "    json_data = file.read()\n",
        "\n",
        "    print(json_data)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAwUjOvdckkq",
        "outputId": "36acf86f-bb74-4c2d-a22b-2777e9bcf447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"name\": \"John\",\n",
            "    \"age\": 28,\n",
            "    \"gender\": \"Male\",\n",
            "    \"address\": {\n",
            "      \"street\": \"123 Main St\",\n",
            "      \"city\": \"New York\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Jane\",\n",
            "    \"age\": 32,\n",
            "    \"gender\": \"Female\",\n",
            "    \"address\": {\n",
            "      \"street\": \"456 Elm St\",\n",
            "      \"city\": \"San Francisco\"\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create a sample dataframe\n",
        "data={\n",
        "    \"name\":[\"John\",\"Jane\",\"Mike\",\"Emily\"],\n",
        "    \"age\":[28,32,45,23],\n",
        "    \"gender\":[\"Male\",\"Female\",\"Male\",\"Female\"],\n",
        "    \"City\":[\"New York\",\"San Francisco\",\"Los Angeles\",\"Chicago\"]\n",
        "}\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "\n",
        "# save the dataframe to a csv file\n",
        "csv_file_path=\"/content/sample_people.csv\"\n",
        "df.to_csv(csv_file_path,index=False)\n",
        "\n",
        "# confirm the file has been created\n",
        "print(f\"CSV file created at {csv_file_path}\")\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize the SparkSession\n",
        "spark=SparkSession.builder.appName(\"Create view example\").getOrCreate()\n",
        "\n",
        "# Load the csv file into a pyspark dataframe\n",
        "df_people=spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\", \"true\").load(csv_file_path)\n",
        "\n",
        "df_people.show()\n",
        "\n",
        "# create a temporary view\n",
        "df_people.createOrReplaceTempView(\"people_temp_view\")\n",
        "\n",
        "result_temp_view=spark.sql(\"SELECT name, age, gender, city FROM people_temp_view WHERE age>30 \")\n",
        "result_temp_view.show()\n",
        "\n",
        "# create a global temporary view\n",
        "df_people.createOrReplaceGlobalTempView(\"people_global_view\")\n",
        "\n",
        "result_global_view=spark.sql(\"SELECT name, age, gender, city FROM global_temp.people_global_view WHERE age<30 \")\n",
        "result_global_view.show()\n",
        "\n",
        "spark.catalog.listTables()\n",
        "\n",
        "spark.catalog.dropTempView(\"people_temp_view\")\n",
        "\n",
        "spark.catalog.dropGlobalTempView(\"people_global_view\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4zpHT4ljjHy",
        "outputId": "7ecabaa0-c1fd-4fdf-f093-be7b562d76ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created at /content/sample_people.csv\n",
            "+-----+---+------+-------------+\n",
            "| name|age|gender|         City|\n",
            "+-----+---+------+-------------+\n",
            "| John| 28|  Male|     New York|\n",
            "| Jane| 32|Female|San Francisco|\n",
            "| Mike| 45|  Male|  Los Angeles|\n",
            "|Emily| 23|Female|      Chicago|\n",
            "+-----+---+------+-------------+\n",
            "\n",
            "+----+---+------+-------------+\n",
            "|name|age|gender|         city|\n",
            "+----+---+------+-------------+\n",
            "|Jane| 32|Female|San Francisco|\n",
            "|Mike| 45|  Male|  Los Angeles|\n",
            "+----+---+------+-------------+\n",
            "\n",
            "+-----+---+------+--------+\n",
            "| name|age|gender|    city|\n",
            "+-----+---+------+--------+\n",
            "| John| 28|  Male|New York|\n",
            "|Emily| 23|Female| Chicago|\n",
            "+-----+---+------+--------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS my_database\")\n",
        "spark.sql(\"USE my_database\")\n",
        "spark.sql(\"SHOW DATABASES\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gj9bshq7TiU",
        "outputId": "404780bf-f235-4bed-f569-da79b90d9127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|  namespace|\n",
            "+-----------+\n",
            "|    default|\n",
            "|my_database|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}